{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2JLjskA7fx+bmJq9M93Ry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduseiti/ia368v_dd_class_06/blob/main/T5_fine_tune_for_doc2query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install evaluate -q\n",
        "!pip install ftfy -q\n",
        "!pip install sentencepiece -q\n",
        "!pip install sacrebleu -q\n",
        "!pip install comet_ml -q"
      ],
      "metadata": {
        "id": "IyoODiJf7UDV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_FOLDER=\"drive/MyDrive/unicamp/ia368v_dd/aula_06\"\n",
        "\n",
        "API_KEYS_FILE=\"/content/drive/MyDrive/unicamp/ia368v_dd/api_keys_20230324.json\"\n",
        "\n",
        "TRAIN_OUTPUT_FOLDER=\"./trained_model\"\n",
        "MS_MARCO_SPLIT=\"ms_marco_tiny_data_split.pkl\"\n",
        "\n",
        "MS_MARCO_TINY_URL=\"https://storage.googleapis.com/unicamp-dl/ia368dd_2023s1/msmarco/msmarco_triples.train.tiny.tsv\"\n",
        "\n",
        "LINK_WITH_COMET=True"
      ],
      "metadata": {
        "id": "gB0nBfaiLYJC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "import ftfy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import pickle\n",
        "\n",
        "if LINK_WITH_COMET:\n",
        "    from comet_ml import Experiment"
      ],
      "metadata": {
        "id": "J1H5lQXWbFF5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(WORKING_FOLDER)"
      ],
      "metadata": {
        "id": "mFNsI1WXLtsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d37be70-4e4b-406a-9e0d-1380c8ed3089"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link with comet-ml"
      ],
      "metadata": {
        "id": "YcuHmBPDaDLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if LINK_WITH_COMET:\n",
        "    with open(API_KEYS_FILE) as inputFile:\n",
        "        api_keys = json.load(inputFile)\n",
        "\n",
        "    os.environ[\"COMET_API_KEY\"] = api_keys['comet_ml']\n",
        "    os.environ[\"COMET_LOG_ASSETS\"] = \"True\"\n",
        "    os.environ['COMET_MODE'] = \"ONLINE\"\n",
        "\n",
        "    Experiment(api_key=api_keys['comet_ml'], \n",
        "            project_name=\"causal-language-model-fine-tuning\",\n",
        "            workspace=\"eduseiti\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXxEFPRTaBf4",
        "outputId": "19278c09-a22a-40b0-f75c-a06ac87528f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
            "COMET INFO: Couldn't find a Git repository in '/content/drive/MyDrive/unicamp/ia368v_dd/aula_06' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
            "COMET INFO: Experiment is live on comet.com https://www.comet.com/eduseiti/causal-language-model-fine-tuning/7964c297bb2d4576bfa2caaf53772d84\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (AutoTokenizer, \n",
        "                          AutoModelForSeq2SeqLM, \n",
        "                          Seq2SeqTrainer,\n",
        "                          Seq2SeqTrainingArguments,\n",
        "                          TrainerCallback, \n",
        "                          get_cosine_with_hard_restarts_schedule_with_warmup,\n",
        "                          DataCollatorForSeq2Seq,\n",
        "                          T5Tokenizer, \n",
        "                          T5Model\n",
        "                          )\n",
        "\n",
        "import torch\n",
        "\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "4IGkkxJCjxef"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "wgP6ie7r_uqD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the MS MARCO data split, if available"
      ],
      "metadata": {
        "id": "1Gtj85x8yiCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(MS_MARCO_SPLIT):\n",
        "    with open(MS_MARCO_SPLIT, \"rb\") as inputFile:\n",
        "        ms_marco_data = pickle.load(inputFile)\n",
        "\n",
        "    train_df = ms_marco_data['train']\n",
        "    validation_df = ms_marco_data['validation']\n",
        "else:\n",
        "    print(\"Need to import and fix the training dataset...\")"
      ],
      "metadata": {
        "id": "g_XrVNA7yl5-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and fix training dataset"
      ],
      "metadata": {
        "id": "oR10gOwEh83h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not 'train_df' in locals():\n",
        "    if not os.path.exists(os.path.basename(MS_MARCO_TINY_URL)):\n",
        "        !wget {MS_MARCO_TINY_URL}\n",
        "    else:\n",
        "        print(\"Training dataset already downloaded...\")\n",
        "\n",
        "    ms_df = pd.read_csv(os.path.basename(MS_MARCO_TINY_URL), sep=\"\\t\", header=None, names=['topic', 'positive', 'negative'])\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "    display(ms_df.head())\n",
        "\n",
        "    ms_df['positive'] = ms_df['positive'].apply(lambda text: ftfy.fix_text(text))\n",
        "    ms_df = ms_df.drop('negative', axis=1)\n",
        "\n",
        "else:\n",
        "    print(\"Data split has already been loaded...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEB5xlBIYL1Q",
        "outputId": "f6252514-efd2-429c-ddff-58ad282b9816"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split has already been loaded...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split evaluation part"
      ],
      "metadata": {
        "id": "DvWpFpGpwaFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not 'train_df' in locals():\n",
        "    print(\"ms_df.shape={}\".format(ms_df.shape))\n",
        "\n",
        "    split_entries = np.random.choice(list(range(ms_df.shape[0])), 1000, replace=False)\n",
        "\n",
        "    train_df = ms_df.iloc[np.setdiff1d(list(range(ms_df.shape[0])), split_entries)].reset_index(drop=True)\n",
        "    validation_df = ms_df.iloc[split_entries].reset_index(drop=True)\n",
        "    \n",
        "    print(\"train_df.shape={}\".format(train_df.shape))\n",
        "    print(\"validation_df.shape={}\".format(validation_df.shape))\n",
        "    \n",
        "    with open(MS_MARCO_SPLIT, \"wb\") as outputFile:\n",
        "        pickle.dump({'train': train_df, \n",
        "                    'validation': validation_df}, outputFile, pickle.HIGHEST_PROTOCOL)\n",
        "        \n",
        "else:\n",
        "    print(\"Data split has already been loaded...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVj26xQNwaBm",
        "outputId": "f039bb02-5539-42ee-9c40-d6cdc0a01968"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split has already been loaded...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tune the T5-base model for the query generation"
      ],
      "metadata": {
        "id": "ONzoumZjc5W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Doc2queryFinetuning(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, ms_df, tokenizer):\n",
        "\n",
        "        self.tokenized_topics = tokenizer(ms_df['topic'].tolist(), return_length=True)\n",
        "        self.tokenized_passage = tokenizer(ms_df['positive'].tolist(), return_length=True)\n",
        "\n",
        "        print(\"Topics tokens size stats:\\n{}\\n\".format(stats.describe(self.tokenized_topics['length'])))\n",
        "        print(\"Passages tokens size stats:\\n{}\\n\".format(stats.describe(self.tokenized_passage['length'])))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_topics['input_ids'])\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {'input_ids': self.tokenized_passage['input_ids'][index],\n",
        "                'attention_mask': self.tokenized_passage['attention_mask'][index],\n",
        "                'labels': self.tokenized_topics['input_ids'][index]}"
      ],
      "metadata": {
        "id": "4X2_jX_tw3Vr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainerCallback(TrainerCallback):\n",
        "\n",
        "    def __init__(self, best_validation_yet=99999, model=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.best_validation_metric = best_validation_yet\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "    def on_evaluate(self, args, state, control, model=None, metrics=None, **kwargs):\n",
        "        print(metrics.keys())\n",
        "\n",
        "        print(\"metrics['eval_loss']={}\".format(metrics['eval_loss']))\n",
        "        print(\"metrics['eval_bleu']={}\".format(metrics['eval_bleu']))\n",
        "\n",
        "\n",
        "        if metrics['eval_bleu'] > self.best_validation_metric:\n",
        "            self.model.save_pretrained(os.path.join(TRAIN_OUTPUT_FOLDER, \n",
        "                                                    \"checkpoint-{}-{:.4f}\".format(state.global_step,\n",
        "                                                                                  metrics['eval_bleu'])))\n",
        "            self.best_validation_metric = metrics['eval_bleu']"
      ],
      "metadata": {
        "id": "xiR4Dm69w3QB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare T5 model"
      ],
      "metadata": {
        "id": "Cyv1yI_xw2hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhGbxDBGkCXf",
        "outputId": "019f6f3f-204c-4309-b3bb-4014a0cef63f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpe6QbnI6a81",
        "outputId": "3ab7773d-2bc8-43eb-bb9b-9caa5e1ab38f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "id": "L3YKKvEUlpkM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the datasets"
      ],
      "metadata": {
        "id": "Cqq9J6BkzqUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Doc2queryFinetuning(train_df, tokenizer)\n",
        "eval_dataset = Doc2queryFinetuning(validation_df, tokenizer)"
      ],
      "metadata": {
        "id": "kX75h3oCw3Kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb0312c-09f6-426d-c15b-fb81d89a60ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics tokens size stats:\n",
            "DescribeResult(nobs=10000, minmax=(3, 57), mean=9.5105, variance=11.948684618461847, skewness=1.7547439898740915, kurtosis=10.741828171750589)\n",
            "\n",
            "Passages tokens size stats:\n",
            "DescribeResult(nobs=10000, minmax=(14, 326), mean=86.9099, variance=1264.7692589158914, skewness=1.140892273381897, kurtosis=1.6057605062545974)\n",
            "\n",
            "Topics tokens size stats:\n",
            "DescribeResult(nobs=1000, minmax=(3, 29), mean=9.434, variance=11.218862862862863, skewness=1.3393629730350802, kurtosis=4.007153813445774)\n",
            "\n",
            "Passages tokens size stats:\n",
            "DescribeResult(nobs=1000, minmax=(16, 261), mean=87.08, variance=1265.3289289289291, skewness=1.1804618158884206, kurtosis=1.6154309574375878)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This part was taken from the [`run_translation.py`](https://github.com/huggingface/transformers/blob/main/examples/pytorch/translation/run_translation.py) script."
      ],
      "metadata": {
        "id": "Y9VXQsi5BBWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "xRC29Hizk56U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "id": "Nj8a-g2jBy5G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    # print(\"len(preds)={}\".format(len(preds)))\n",
        "\n",
        "    # for i in range(len(preds)):\n",
        "    #     print(\"len(preds[{}])={}\".format(i, len(preds[i])))\n",
        "    #     print(\"preds[{}].shape={}\".format(i, preds[i].shape))\n",
        "    #     print(\"preds[i]={}\".format(preds[i]))\n",
        "\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    print(\"compute_metrics. preds.shape={}\".format(preds.shape))\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    \n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "doB4B3SVA4s_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=26\n",
        "gradient_accumulation_steps=8\n",
        "epochs=100"
      ],
      "metadata": {
        "id": "kT5rUueI658D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params = Seq2SeqTrainingArguments(output_dir=TRAIN_OUTPUT_FOLDER,\n",
        "                                           num_train_epochs=epochs,\n",
        "                                           per_device_train_batch_size=batch_size,\n",
        "                                           per_device_eval_batch_size=batch_size,\n",
        "                                           gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "                                           evaluation_strategy='steps',\n",
        "                                           eval_steps=50,\n",
        "                                           save_strategy='steps',\n",
        "                                           save_steps=1000,\n",
        "                                           logging_strategy='steps',\n",
        "                                           logging_steps=10,\n",
        "                                           save_total_limit=10,\n",
        "                                           # report_to='comet_ml',\n",
        "                                           # dataloader_num_workers=2,\n",
        "                                           dataloader_pin_memory=True,\n",
        "                                           predict_with_generate=True,\n",
        "                                           fp16=True)"
      ],
      "metadata": {
        "id": "99L0Mq_p7s4M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pad_token_id = -100\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=label_pad_token_id,\n",
        "    pad_to_multiple_of=8 if training_params.fp16 else None,\n",
        ")"
      ],
      "metadata": {
        "id": "FsmNhge3AIRP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_callback = CustomTrainerCallback(best_validation_yet=-1, \n",
        "                                         model=model)"
      ],
      "metadata": {
        "id": "phSscTZI3hO4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_steps = epochs * int(len(train_dataset) // (batch_size * gradient_accumulation_steps))\n",
        "\n",
        "optimzer = torch.optim.AdamW(model.parameters(), lr=5e-6, weight_decay=1e-3)\n",
        "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimzer, \n",
        "                                                               0,\n",
        "                                                               num_training_steps, \n",
        "                                                               num_cycles=10)"
      ],
      "metadata": {
        "id": "8y9rWOcRbZoV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_steps // 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMDCHMew-9IL",
        "outputId": "e81009cb-2f76-42be-bdbd-2bad2f341158"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "960"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(model=model,\n",
        "                         args=training_params,\n",
        "                         train_dataset=train_dataset,\n",
        "                         eval_dataset=eval_dataset,\n",
        "                         data_collator=data_collator,\n",
        "                         callbacks=[trainer_callback],\n",
        "                         optimizers=(optimzer, scheduler),\n",
        "                         tokenizer=tokenizer,\n",
        "                         compute_metrics=compute_metrics\n",
        "                         )"
      ],
      "metadata": {
        "id": "77Sgz4OB8nMp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mefCKkW60Ko0",
        "outputId": "4b616940-da99-44d2-d2be-19e6a13a980b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMET INFO: ---------------------------------------------------------------------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------------------------------------------------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.com/eduseiti/causal-language-model-fine-tuning/7964c297bb2d4576bfa2caaf53772d84\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 2\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO:     source_code         : 1\n",
            "COMET INFO: \n",
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
            "COMET INFO: Couldn't find a Git repository in '/content/drive/MyDrive/unicamp/ia368v_dd/aula_06' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
            "COMET INFO: Experiment is live on comet.com https://www.comet.com/eduseiti/huggingface/67ccc002acea4f6089f7627dd27594bd\n",
            "\n",
            "COMET ERROR: Failed to extract scalar from SummaryWriter.add_hparams()\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/4800 19:58 < 4:42:27, 0.26 it/s, Epoch 6.61/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.585200</td>\n",
              "      <td>3.973049</td>\n",
              "      <td>1.079800</td>\n",
              "      <td>17.978000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.484000</td>\n",
              "      <td>2.923510</td>\n",
              "      <td>1.501000</td>\n",
              "      <td>17.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.682300</td>\n",
              "      <td>2.377275</td>\n",
              "      <td>2.069200</td>\n",
              "      <td>13.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.491700</td>\n",
              "      <td>2.280683</td>\n",
              "      <td>2.519800</td>\n",
              "      <td>12.344000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.767100</td>\n",
              "      <td>2.279149</td>\n",
              "      <td>2.533200</td>\n",
              "      <td>12.312000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.754000</td>\n",
              "      <td>2.279186</td>\n",
              "      <td>2.533600</td>\n",
              "      <td>12.310000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute_metrics. preds.shape=(1000, 20)\n",
            "dict_keys(['eval_loss', 'eval_bleu', 'eval_gen_len', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
            "metrics['eval_loss']=3.9730489253997803\n",
            "metrics['eval_bleu']=1.0798\n",
            "compute_metrics. preds.shape=(1000, 20)\n",
            "dict_keys(['eval_loss', 'eval_bleu', 'eval_gen_len', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
            "metrics['eval_loss']=2.9235098361968994\n",
            "metrics['eval_bleu']=1.501\n",
            "compute_metrics. preds.shape=(1000, 20)\n",
            "dict_keys(['eval_loss', 'eval_bleu', 'eval_gen_len', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
            "metrics['eval_loss']=2.377274990081787\n",
            "metrics['eval_bleu']=2.0692\n",
            "compute_metrics. preds.shape=(1000, 20)\n",
            "dict_keys(['eval_loss', 'eval_bleu', 'eval_gen_len', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
            "metrics['eval_loss']=2.2806830406188965\n",
            "metrics['eval_bleu']=2.5198\n",
            "compute_metrics. preds.shape=(1000, 20)\n",
            "dict_keys(['eval_loss', 'eval_bleu', 'eval_gen_len', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
            "metrics['eval_loss']=2.279148817062378\n",
            "metrics['eval_bleu']=2.5332\n",
            "compute_metrics. preds.shape=(1000, 20)\n",
            "dict_keys(['eval_loss', 'eval_bleu', 'eval_gen_len', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
            "metrics['eval_loss']=2.2791857719421387\n",
            "metrics['eval_bleu']=2.5336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment.end()"
      ],
      "metadata": {
        "id": "pueVwXfaaydQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}